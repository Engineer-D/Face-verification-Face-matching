'''
    Date: 5-5-2021
    Name: Engineer-D
    Idea: OpenCV face detection
    Special Thanks: PyImageSearch
'''

# import the necesseary packages
import numpy as np
import argparse
import time
import cv2
import os

# Construct the argument parser and parse argument
ap = argparse.ArgumentParser()
# add argument for the images
ap.add_argument("-i","--image", type = str, required = True,\
    help = "Path to input image that we want to detect and extract")
ap.add_argument("-p","--prototxt", required = True,\
    help = "Path to caffe 'deploy' prototxt file")
ap.add_argument("-m","--model", required = True,\
    help = "Path to caffe pre-trained model")
ap.add_argument("-c", "--confidence", type = float, default = 0.5,\
    help = "minimum probablilty to filter weak detections")
ap.add_argument("-n", "--iter", type = int, default = 10,\
    help = "no of Grabcut iteration (larger value ==> slower runtime)")
args = vars(ap.parse_args())

# *************** Load Serialied Model into disk *****************
print("[INFO} Loading Model ...")
net = cv2.dnn.readNetFromCaffe(args['prototxt'], args['model'])

# *************** Load Input Image ****************************
# Load the image and construct  an input blob for the image by resizing
# to a fixed 300X300 pixels and then normalizing it
image = cv2.imread(args['image'])
image_cp = image.copy()
(h,w) = image.shape[:2]
blob = cv2.dnn.blobFromImage(cv2.resize(image, (300,300)), 1.0,\
    (300, 300), (104.0, 177.0, 123.0))

# Allocate Memory for the output mask generated by grabcut -- this mask 
# should have the same spatial dimensions as the input image
mask = np.zeros(image.shape[:2], dtype = "uint8")

# pass the blob through the network and obtain the detctions and predictions
print("[INFO] Computing Face Detections ...")
net.setInput(blob)
detections = net.forward()

# Get the detection with the highest confidence

#confidence = detections[0, 0, 0, 2] #the confidence has been arranged 
# so [0,0,0*,2] 0* is the highest confidence 
box = detections[0, 0, 0, 3:7] * np.array([w, h, w, h])
(startX, startY, endX, endY) = box.astype("int")

# Draw the Bounding Box of the face along with the associated probabity
cv2.rectangle(image_cp, (startX-30, startY-30), (endX+30, endY+30), (0, 0, 255), 2)

# Show the Output image
cv2.imshow("Face Detected Image", image_cp)
cv2.waitKey(0)

# Allocate mermory for two arrays that the grabcut algorithm internally uses
# when segmenting the foreground from the background

rect = (startX-30, startY-30, endX+30, endY+30)
fgModel = np.zeros((1,65), dtype='float')
bgModel = np.zeros((1,65), dtype='float')

#apply grabcut using the bounding box segmentation method
start = time.time()
(mask, bgModel, fgModel) = cv2.grabCut(image, mask, rect,\
    bgModel, fgModel, iterCount = args['iter'], mode = cv2.GC_INIT_WITH_RECT)
end = time.time()
print("[INFO] applying grabCut took {:.2f} seconds".format(end-start))

# the output mask has four possible output values, marking each pixel in the mask as
# (1) Definite Background (2) Definite Foreground (3) Probable Background (4) Probable
# foreground

values = (
    ("Definite Background", cv2.GC_BGD),
    ("Probable Background", cv2.GC_PR_BGD),
    ("Definite Foreground", cv2.GC_FGD),
    ("Probable Foreground", cv2.GC_PR_FGD),   
)

'''
# loop over the possible Grabcut mask values
for (name, value) in values:
    # Construct a mask that's for the current value
    print("[INFO] Showing mask for '{}'".format(name))
    valueMask = (mask == value).astype("uint8") * 255

    # Display the mask so we can visualize it
    cv2.imshow(name, valueMask)
    cv2.waitKey(0)
'''

# We'll set all definite background and probable background pixels to 0
# while definite foreground and probable foreground pixels are set to 1

outputMask = np.where((mask == cv2.GC_BGD) | (mask == cv2.GC_PR_BGD),0, 1)

# scale the mask from the range [0, 1] to [0, 255]
outputMask = (outputMask * 255).astype('uint8')

# apply a bitwise AND to the image using our mask generated by 
# Grabcut to generate our final output image
output = cv2.bitwise_and(image, image, mask=outputMask)

# Show the input image followed by the mask and output generated 
# by grabcut and bitwise masking

#cv2.imshow("Input", image)
#cv2.imshow("GrabCut Mask", outputMask)
cv2.imshow("GrabCut Output", output)
cv2.waitKey(0)

################********* The END *************#######################