'''
    Date: 5-5-2021
    Name: Engineer-D
    Idea: OpenCV face detection
    Special Thanks: PyImageSearch
'''

'''
Tips:

Modularize your code:
    * Face Detection
    * Face Extraction
    * Image reading
Try to see if you can handle input of 2 images easily
'''


# import the necesseary packages
import numpy as np
import argparse
import time
import cv2
import os
import FaceVerification as fv
import warnings
warnings.filterwarnings('ignore')

# Construct the argument parser and parse argument
ap = argparse.ArgumentParser()
# add argument for the images
ap.add_argument("-ri","--r_image", type = str, required = True,\
    help = "Path to input reference image that we want to compare")
ap.add_argument("-i","--image", type= str, required=True,\
    help= "Path to input image we want to compare")
ap.add_argument("-p","--prototxt", required = True,\
    help = "Path to caffe 'deploy' prototxt file")
ap.add_argument("-m","--model", required = True,\
    help = "Path to caffe pre-trained model")
ap.add_argument("-c", "--confidence", type = float, default = 0.5,\
    help = "minimum probablilty to filter weak detections")
ap.add_argument("-n", "--iter", type = int, default = 10,\
    help = "no of Grabcut iteration (larger value ==> slower runtime)")
args = vars(ap.parse_args())

# *************** Load Serialied Model into disk *****************
print("[INFO} Loading Model ...")
net = cv2.dnn.readNetFromCaffe(args['prototxt'], args['model'])

# *************** Load Input Image ****************************
# Create a Function to help read in images
def read_image(image, resized = (300, 300)):
    '''
    This Function substitutes for this code
        image = cv2.imread(args['image'])
        image_cp = image.copy()
        (h,w) = image.shape[:2]
        blob = cv2.dnn.blobFromImage(cv2.resize(image, (300,300)), 1.0,\
            (300, 300), (104.0, 177.0, 123.0))
    '''
    image = cv2.imread(image)
    (h,w) = image.shape[:2]
    blob = cv2.dnn.blobFromImage((cv2.resize(image, resized)), 1.0,\
        resized, (104.0, 177.0, 123.0))
    return image,(h,w),blob

# Load the image and construct  an input blob for the image by resizing
# to a fixed 300X300 pixels and then normalizing it
r_image, (r_h,r_w), r_blob = read_image(args['r_image'])
image, (h,w), blob = read_image(args['image'])

# *********************Face Detection Here**********************************
def face_detection(net, blob):
    print(f"[INFO] Computing Face Detections ...")
    # pass the blob through the network and obtain the detctions and predictions
    net.setInput(blob)
    detections = net.forward()

    # Get the detection with the highest confidence
    #confidence = detections[0, 0, 0, 2] #the confidence has been arranged 
    # so [0,0,0*,2] 0* is the highest confidence 
    box = detections[0, 0, 0, 3:7] * np.array([w, h, w, h])
    return box

# defining the bounding box
r_box = face_detection(net, r_blob)
box = face_detection(net, blob)
(r_startX, r_startY, r_endX, r_endY) = r_box.astype("int")
(startX, startY, endX, endY) = box.astype("int")

# Draw the Bounding Box of the face along with the associated probabity
r_image_cp = r_image.copy()
image_cp = image.copy()
cv2.rectangle(r_image_cp, (r_startX-30, r_startY-30),\
    (r_endX+30, r_endY+30), (0, 0, 255), 2)
cv2.rectangle(image_cp, (startX-30, startY-30),\
    (endX+30, endY+30), (0, 0, 255), 2)

# Show the Output image
cv2.imshow("Reference Face Detected Image", r_image_cp)
cv2.imshow("Face Detected Image", image_cp)
cv2.waitKey(0)

# ********************* Face Extraction ******************************
'''
def extract_face(image, resize=(224,224)):
    image = cv2.imread(image)

    faces = detector.detect_faces(image)
    x1, y1, width, height = faces[0]['box']
    x2, y2 = x1 + width, y1 + height

    face_boundary = image[y1:y2, x1:x2]

    face_image = cv2.resize(face_boundary, resize)

    return face_image
''' 
def extract_face(image, iter,resize=(224,224)):
    #image = cv2.resize(image, resize)
    # Allocate Memory for the output mask generated by grabcut -- this mask 
    # should have the same spatial dimensions as the input image
    mask = np.zeros(image.shape[:2], dtype = "uint8")

    # Allocate mermory for two arrays that the grabcut algorithm internally uses
    # when segmenting the foreground from the background

    rect = (startX-30, startY-30, endX+30, endY+30)
    fgModel = np.zeros((1,65), dtype='float')
    bgModel = np.zeros((1,65), dtype='float')

    #apply grabcut using the bounding box segmentation method
    start = time.time()
    (mask, bgModel, fgModel) = cv2.grabCut(image, mask, rect,\
        bgModel, fgModel, iterCount = iter, mode = cv2.GC_INIT_WITH_RECT)
    end = time.time()
    print("[INFO] applying grabCut took {:.2f} seconds".format(end-start))

    # the output mask has four possible output values, marking each pixel in the mask as
    # (1) Definite Background (2) Definite Foreground (3) Probable Background (4) Probable
    # foreground

    values = (
        ("Definite Background", cv2.GC_BGD),
        ("Probable Background", cv2.GC_PR_BGD),
        ("Definite Foreground", cv2.GC_FGD),
        ("Probable Foreground", cv2.GC_PR_FGD),   
    )

    '''
    # loop over the possible Grabcut mask values
    for (name, value) in values:
        # Construct a mask that's for the current value
        print("[INFO] Showing mask for '{}'".format(name))
        valueMask = (mask == value).astype("uint8") * 255

        # Display the mask so we can visualize it
        cv2.imshow(name, valueMask)
        cv2.waitKey(0)
    '''

    # We'll set all definite background and probable background pixels to 0
    # while definite foreground and probable foreground pixels are set to 1

    outputMask = np.where((mask == cv2.GC_BGD) | (mask == cv2.GC_PR_BGD),0, 1)

    # scale the mask from the range [0, 1] to [0, 255]
    outputMask = (outputMask * 255).astype('uint8')

    # apply a bitwise AND to the image using our mask generated by 
    # Grabcut to generate our final output image
    output = cv2.bitwise_and(image, image, mask=outputMask)

    return output

r_output = extract_face(r_image, iter= args['iter'])
output = extract_face(image, iter= args['iter'])

# Show the input image followed by the mask and output generated 
# by grabcut and bitwise masking

#cv2.imshow("Input", image)
#cv2.imshow("GrabCut Mask", outputMask)
cv2.imshow("Reference GrabCut Output", r_output)
cv2.imshow("GrabCut Output", output)
cv2.waitKey(0)

#face_image = cv2.resize(face_boundary, resize)
r_output = cv2.resize(r_output, (224,224))
output = cv2.resize(output, (224,224))
faces = [r_output, output]
print(fv.get_similarity(faces))
################********* The END *************#######################